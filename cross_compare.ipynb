{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eedb5f3d-031e-43a6-840a-d9e01bf4f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyphenate import hyphenate_word\n",
    "from model import sp_syllabler\n",
    "import pickle\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ca587b1-02b5-478e-b0a2-23d7a5b5abca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "# setting hot func\n",
    "\n",
    "def convert_to_hot(syl_word):\n",
    "    hot = []\n",
    "    i = 0\n",
    "    while  i < len(syl_word):\n",
    "        if i == len(syl_word) - 1:\n",
    "            hot += [1]\n",
    "            return hot\n",
    "        if syl_word[i+1] == '-':\n",
    "            hot += [2]\n",
    "            i += 2\n",
    "        else:\n",
    "            hot += [1]\n",
    "            i += 1\n",
    "    return hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38cbf053-d7da-425e-99d5-0d96e1231309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5\n",
    "# brier func\n",
    "def calc_brier(attempted, probability):\n",
    "    total = 0\n",
    "    sum_brier = 0\n",
    "    for word in attempted:\n",
    "        for c in attempted:\n",
    "            total += 1\n",
    "            if c == 2:\n",
    "                sum_brier += (probability - 1)**2\n",
    "            elif c == 1:\n",
    "                sum_brier += (probability - 0)**2\n",
    "    return (1./total)*(sum_brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5158751-cef0-4c0e-a6f2-a056bafc5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8\n",
    "\n",
    "def inconsistency_grab(attempts, reals, filename = 'cross_compare/incorrect_syls.txt'):\n",
    "    global converted_back_to_eng\n",
    "    sum_lev = 0\n",
    "    incorrect_counter = 0\n",
    "    incorrect_syl_count = 0\n",
    "    file = open(filename, 'w+', encoding='utf-8')\n",
    "    file.write('Attempt' + '\\t' + 'Real' + '\\n')\n",
    "    for i in range(0, len(attempts)):\n",
    "        if attempts[i] != reals[i]:\n",
    "            incorrect_counter += 1\n",
    "            a = shitter.insert_syl(converted_back_to_eng[i], attempts[i])\n",
    "            r = shitter.insert_syl(converted_back_to_eng[i], reals[i])\n",
    "            if len(a.split('-')) != len(r.split('-')):\n",
    "                incorrect_syl_count += 1\n",
    "            sum_lev += edit_distance(a,r,substitution_cost=1, transpositions=True)\n",
    "            file.write(a + '\\t' + r + '\\n')\n",
    "    file.write(\"Words with errors: %i\"%incorrect_counter +'\\n')\n",
    "    file.write(\"Words with incorrect number of syllables: %i\"%incorrect_syl_count +'\\n')\n",
    "    file.write(\"Total evluated: %i\"%len(attempts) +'\\n')\n",
    "    file.write(\"Perfect accuracy: %.2f\"%((len(attempts) - incorrect_counter)/len(attempts)) +'\\n')\n",
    "    file.write(\"Number of syllables accuracy: %.2f\"%((len(attempts) - incorrect_syl_count)/len(attempts)) +'\\n')\n",
    "    file.write(\"Average Levenshtein Distance(across incorrect words): %.2f\"%(sum_lev/incorrect_counter) +'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fddc73db-3381-4d8f-9c25-2ad3a601ddd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "def calc_f1(attempted, true, filename = 'cross_compare/evaluation_output_single_pen.txt'):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    correct_num_char = 0\n",
    "    total_checked = 0\n",
    "    evaluation_file = open(filename, 'w+')\n",
    "    for i in range(0, len(attempted)):\n",
    "        total_checked += 1\n",
    "        if (len(attempted[i]) == len(true[i])):\n",
    "            correct_num_char += 1\n",
    "            for j in range(0, len(attempted[i])):\n",
    "                if(attempted[i][j] == true[i][j]):\n",
    "                    if true[i][j] == 1:\n",
    "                        true_neg += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        true_pos += 1\n",
    "                else:\n",
    "                    if true[i][j] == 1:\n",
    "                        false_pos += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        false_neg += 1\n",
    "    evaluation_file.write(\"Total checked: \" + str(total_checked) + '\\n')\n",
    "    evaluation_file.write(\"Num correctly evaluated character count: \" +  str(correct_num_char) + '\\n')\n",
    "    evaluation_file.write(\"True positives: \" + str(true_pos) + '\\n')\n",
    "    evaluation_file.write(\"True negatives: \" + str(true_neg) + '\\n')\n",
    "    evaluation_file.write(\"False positives: \" + str(false_pos) + '\\n')\n",
    "    evaluation_file.write(\"False negatives: \" + str(false_neg) + '\\n')\n",
    "    brier = calc_brier(attempted, probability=0.2)\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    f_one = 2/((1/precision)+(1/recall))\n",
    "    evaluation_file.write(\"precision: \" + str(precision) + '\\n')\n",
    "    evaluation_file.write(\"recall: \" + str(recall) +  '\\n')\n",
    "    evaluation_file.write(\"F1 scores: \" + str(f_one) + '\\n')\n",
    "    evaluation_file.write(\"Brier score: \" + str(brier) + '\\n')\n",
    "    evaluation_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69b504c5-72cd-4e33-92b7-8433e69a9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# grabbing validation data and converting back to English\n",
    "\n",
    "with open('data/ox/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "\n",
    "with open('data/ox/x_val_ortho.pkl', 'rb') as file:\n",
    "    x_val_ortho = pickle.load(file)\n",
    "\n",
    "with open('data/ox/y_val.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "converted_back_to_eng = []\n",
    "for x in x_val_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    converted_back_to_eng += [real_word]    \n",
    "    \n",
    "shitter = sp_syllabler(e2i_ortho= e2i_ortho, ortho_input_size=20,latent_dim=32,embed_dim=32 ,max_feat=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d02cd1f-7fd2-4326-a999-4abfe72bcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# syllabification using liang's algorithm\n",
    "# one-hot encode results\n",
    "\n",
    "liang_attempts = []\n",
    "for word in converted_back_to_eng:\n",
    "    liang_attempts += ['-'.join(hyphenate_word(word))]\n",
    "\n",
    "liang_attempts_hot_encoded = [convert_to_hot(word) for word in liang_attempts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97d1713c-29c7-4188-a8ef-42d459cd820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# f1 scoring liang\n",
    "# incorrect syl grabbing liang\n",
    "# omitting padding in reals\n",
    "\n",
    "reals = []\n",
    "for x in y_val:\n",
    "    reals += [[i for i in x if i !=0]]\n",
    "calc_f1(liang_attempts_hot_encoded, reals, filename='cross_compare/liang_f1.txt')\n",
    "inconsistency_grab(liang_attempts_hot_encoded, reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d36ac9-d5cd-4ca5-84e3-d5ee7c8834eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10706\n",
      "8955\n"
     ]
    }
   ],
   "source": [
    "nums_of_2 = 0\n",
    "for word in y_val:\n",
    "    for c in word:\n",
    "        if c == 2:\n",
    "            nums_of_2 += 1\n",
    "print(nums_of_2)\n",
    "\n",
    "nums_of_2_liang = 0\n",
    "for word in liang_attempts_hot_encoded:\n",
    "    for c in word:\n",
    "        if c == 2:\n",
    "            nums_of_2_liang += 1\n",
    "print(nums_of_2_liang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f35ba9a-8385-4dba-993c-541f93d90c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "length_mismatches = []\n",
    "mismatch_indexes = []\n",
    "\n",
    "for i in range(0, len(liang_attempts_hot_encoded)):\n",
    "    if len(liang_attempts_hot_encoded[i]) != len(reals[i]):\n",
    "        length_mismatches += [(len(liang_attempts_hot_encoded[i]), len(reals[i]))]\n",
    "        mismatch_indexes += [i]\n",
    "print(len(mismatch_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6935e3e-d1e0-4353-b07d-b2dc13c0c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cal', 'iber']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5212f18-cf08-4afa-983d-cf437d8895f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laptop_sketchbook] *",
   "language": "python",
   "name": "conda-env-laptop_sketchbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
